{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning: Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Union\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skops.io as sio\n",
    "from tqdm import tqdm\n",
    "\n",
    "import helpers\n",
    "from helpers import (\n",
    "    CHARTS_DIR, RAW_DATA_DIR, IMPUTER_MODEL_DIR\n",
    ")\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>township_BANDAR BARU SRI PETALING</th>\n",
       "      <th>township_TAMAN TUN DR ISMAIL</th>\n",
       "      <th>township_DAMANSARA HEIGHTS (BUKIT DAMANSARA)</th>\n",
       "      <th>township_TAMAN BUKIT MALURI</th>\n",
       "      <th>township_KEPONG BARU</th>\n",
       "      <th>township_OVERSEAS UNION GARDEN</th>\n",
       "      <th>township_HAPPY GARDEN</th>\n",
       "      <th>township_TAMAN MIDAH</th>\n",
       "      <th>township_ALAM DAMAI</th>\n",
       "      <th>township_TAMAN SRI SINAR</th>\n",
       "      <th>...</th>\n",
       "      <th>tenure_FREEHOLD</th>\n",
       "      <th>floors</th>\n",
       "      <th>rooms</th>\n",
       "      <th>land_area</th>\n",
       "      <th>built_up</th>\n",
       "      <th>price_psf</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2196.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>342.0</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>753.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>398.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3197.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>753.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>531.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4801.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265265</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>1990</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265266</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>218025.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265268</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>235000.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265269</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>518296.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265270 rows Ã— 1905 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        township_BANDAR BARU SRI PETALING  township_TAMAN TUN DR ISMAIL  \\\n",
       "0                                       1                             0   \n",
       "1                                       1                             0   \n",
       "2                                       1                             0   \n",
       "3                                       1                             0   \n",
       "4                                       1                             0   \n",
       "...                                   ...                           ...   \n",
       "265265                                  0                             0   \n",
       "265266                                  0                             0   \n",
       "265267                                  0                             0   \n",
       "265268                                  0                             0   \n",
       "265269                                  0                             0   \n",
       "\n",
       "        township_DAMANSARA HEIGHTS (BUKIT DAMANSARA)  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "...                                              ...   \n",
       "265265                                             0   \n",
       "265266                                             0   \n",
       "265267                                             0   \n",
       "265268                                             0   \n",
       "265269                                             0   \n",
       "\n",
       "        township_TAMAN BUKIT MALURI  township_KEPONG BARU  \\\n",
       "0                                 0                     0   \n",
       "1                                 0                     0   \n",
       "2                                 0                     0   \n",
       "3                                 0                     0   \n",
       "4                                 0                     0   \n",
       "...                             ...                   ...   \n",
       "265265                            0                     0   \n",
       "265266                            0                     0   \n",
       "265267                            0                     0   \n",
       "265268                            0                     0   \n",
       "265269                            0                     0   \n",
       "\n",
       "        township_OVERSEAS UNION GARDEN  township_HAPPY GARDEN  \\\n",
       "0                                    0                      0   \n",
       "1                                    0                      0   \n",
       "2                                    0                      0   \n",
       "3                                    0                      0   \n",
       "4                                    0                      0   \n",
       "...                                ...                    ...   \n",
       "265265                               0                      0   \n",
       "265266                               0                      0   \n",
       "265267                               0                      0   \n",
       "265268                               0                      0   \n",
       "265269                               0                      0   \n",
       "\n",
       "        township_TAMAN MIDAH  township_ALAM DAMAI  township_TAMAN SRI SINAR  \\\n",
       "0                          0                    0                         0   \n",
       "1                          0                    0                         0   \n",
       "2                          0                    0                         0   \n",
       "3                          0                    0                         0   \n",
       "4                          0                    0                         0   \n",
       "...                      ...                  ...                       ...   \n",
       "265265                     0                    0                         0   \n",
       "265266                     0                    0                         0   \n",
       "265267                     0                    0                         0   \n",
       "265268                     0                    0                         0   \n",
       "265269                     0                    0                         0   \n",
       "\n",
       "        ...  tenure_FREEHOLD  floors  rooms  land_area  built_up  price_psf  \\\n",
       "0       ...                0     1.0    NaN     2196.0       NaN      342.0   \n",
       "1       ...                0     2.0    NaN      753.0       NaN      398.0   \n",
       "2       ...                0     2.5    NaN     3197.0       NaN      188.0   \n",
       "3       ...                0     2.0    NaN      753.0       NaN      531.0   \n",
       "4       ...                0     2.5    NaN     4801.0       NaN      250.0   \n",
       "...     ...              ...     ...    ...        ...       ...        ...   \n",
       "265265  ...                0     1.0    2.0      493.0     493.0       71.0   \n",
       "265266  ...                1     1.0    3.0     1454.0    1454.0      150.0   \n",
       "265267  ...                1     1.0    3.0      593.0     593.0      194.0   \n",
       "265268  ...                0     1.0    2.0     1193.0    1193.0      197.0   \n",
       "265269  ...                0     1.0    3.0     1927.0    1927.0      269.0   \n",
       "\n",
       "            price  year  month  day  \n",
       "0        750000.0  2023      6    9  \n",
       "1        300000.0  2023      6    1  \n",
       "2        600000.0  2023      5   29  \n",
       "3        400000.0  2023      5   25  \n",
       "4       1200000.0  2023      5   22  \n",
       "...           ...   ...    ...  ...  \n",
       "265265    35000.0  1990     11   13  \n",
       "265266   218025.0  2005      1   10  \n",
       "265267   115000.0  2008      2   25  \n",
       "265268   235000.0  2009      8   10  \n",
       "265269   518296.0  1995      8   18  \n",
       "\n",
       "[265270 rows x 1905 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_encoded = pd.read_parquet(RAW_DATA_DIR / 'transactions_KL_ckpt4_encoded.parquet')\n",
    "df_transactions_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 265270 entries, 0 to 265269\n",
      "Columns: 1905 entries, township_BANDAR BARU SRI PETALING to day\n",
      "dtypes: float64(6), int32(3), int64(1896)\n",
      "memory usage: 3.8 GB\n"
     ]
    }
   ],
   "source": [
    "df_transactions_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "1909       1\n",
       "1933       1\n",
       "1955       1\n",
       "1959       1\n",
       "1960       7\n",
       "        ... \n",
       "2019    7388\n",
       "2020    6775\n",
       "2021    7492\n",
       "2022    8136\n",
       "2023    2098\n",
       "Name: count, Length: 67, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_encoded['year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concluding Remarks from Data Cleaning 1: Recap\n",
    "1. The following data cleaning steps has been performed:\n",
    "    - Removed address column\n",
    "    - Changed fraction to decimal\n",
    "    - Removed commas in numerical values\n",
    "    - Removed units in numerical values\n",
    "    - Removed exact duplicates\n",
    "    - Removed outliers using HDBSCAN, based on:\n",
    "        - Continuous variables: `land_area`, `built_up`, `price_psf` (3D)\n",
    "        - Ordinal variables: `floors`, `rooms` (2D)\n",
    "2. Investigated missing values in `built_up` and `rooms`\n",
    "    - Investigated correlation and association between features to determine which features to use to impute missing values\n",
    "3. Encoded features for imputation using one hot encoding\n",
    "\n",
    "Next, we should proceed to impute the missing values in `built_up` and `rooms`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values\n",
    "\n",
    "Based on literature, the following imputation methods have been identified:\n",
    "1. Random forest imputation (Jager et al., 2021) for MCAR, MAR and MNAR data in various domain\n",
    "2. Multiple imputation by deterministic regression (Donlen, 2022) for MCAR data in real estate domain\n",
    "3. MissForest (Waljee et al., 2013) for MCAR data in medical domain\n",
    "4. Predictive mean matching, PMM (Heidt, 2019) for MAR data in medical domain\n",
    "5. KNN imputation (Jadhav et al., 2019) for MCAR, MAR and MNAR data in UCI dataset\n",
    "\n",
    "However, when filtered by domain (real estate), only three methods are identified:\n",
    "1. Random forest imputation\n",
    "2. KNN imputation\n",
    "3. Multiple imputation by deterministic regression\n",
    "\n",
    "These are machine learning approaches for imputation, where we treat the features with missing values as target variable and the features without missing values as independent variables. In order to obtain a better overview of the performance of the imputation methods, we use cross validation techniques:\n",
    "1. Split the dataset into train and test, where train are the data with labels and test are the data without labels\n",
    "2. Split the train dataset into train and validation\n",
    "3. Cross validate the train data:\n",
    "    - Create a pipeline with scaler and model\n",
    "    - Run cross validation with scoring\n",
    "    - Output both train and validation scores\n",
    "    - Return the pipeline and cross validation results\n",
    "4. Train and evaluate the model with validation data\n",
    "    - Train the pipeline with train data\n",
    "    - Predict the validation data\n",
    "    - Evaluate the model with validation data\n",
    "5. Evaluate the pipeline with validation data and print out the metrics\n",
    "6. Predict the test data\n",
    "7. Return the imputed dataset and the fitted pipeline\n",
    "\n",
    "References:\n",
    "- Jager et al. (2021): https://www.frontiersin.org/articles/10.3389/fdata.2021.693674/full\n",
    "- Donlen (2022): https://egrove.olemiss.edu/cgi/viewcontent.cgi?article=3744&context=hon_thesis\n",
    "- Waljee et al. (2013): https://bmjopen.bmj.com/content/3/8/e002847.citation-tools\n",
    "- Heidt (2019): https://dc.etsu.edu/cgi/viewcontent.cgi?article=5014&context=etd\n",
    "- Jadhav et al (2019): https://www.tandfonline.com/doi/full/10.1080/08839514.2019.1637138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score,\n",
    "    median_absolute_error, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "Model = Union[RandomForestRegressor, KNeighborsRegressor, RandomForestClassifier, KNeighborsClassifier]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing `built_up`\n",
    "\n",
    "The steps are:\n",
    "1. Remove `rooms` from the dataset as it has too many missing values\n",
    "2. Cross validate for `built_up` using:\n",
    "    - Random forest imputation\n",
    "    - KNN imputation\n",
    "3. Use the better model to impute `built_up`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'built_up'\n",
    "\n",
    "# Split the dataset into train and test, where train are the data with labels and test are the data without labels\n",
    "df_train = df_transactions_encoded[df_transactions_encoded[target].notna()].drop(columns=['rooms']).dropna()\n",
    "df_test = df_transactions_encoded[df_transactions_encoded[target].isna()].drop(columns=['rooms'])\n",
    "\n",
    "# Split the train dataset into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train.drop(columns=[target]), df_train[target], test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_with_pipeline(pipeline: Pipeline, X_train: np.ndarray, y_train: np.ndarray, task: str):\n",
    "\n",
    "    # Cross validate the train data\n",
    "    if task == 'regression':\n",
    "        scoring = ('r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_percentage_error', 'neg_median_absolute_error')\n",
    "    elif task == 'classification':\n",
    "        scoring = ('accuracy', 'balanced_accuracy', 'f1', 'precision', 'recall', 'roc_auc')\n",
    "    else:\n",
    "        scoring = None\n",
    "\n",
    "    cv_results = cross_validate(pipeline, X_train, y_train, cv=5, scoring=scoring, return_train_score=True, n_jobs=4)\n",
    "    \n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross validation for `built_up` using various techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_percentage_error</th>\n",
       "      <th>train_neg_mean_absolute_percentage_error</th>\n",
       "      <th>test_neg_median_absolute_error</th>\n",
       "      <th>train_neg_median_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1221.663679</td>\n",
       "      <td>11.541488</td>\n",
       "      <td>0.824293</td>\n",
       "      <td>0.973771</td>\n",
       "      <td>-357.268651</td>\n",
       "      <td>-136.370194</td>\n",
       "      <td>-4.652190e+15</td>\n",
       "      <td>-1.715361e+15</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200.971122</td>\n",
       "      <td>9.686063</td>\n",
       "      <td>0.798486</td>\n",
       "      <td>0.975722</td>\n",
       "      <td>-379.701082</td>\n",
       "      <td>-131.454077</td>\n",
       "      <td>-5.023980e+15</td>\n",
       "      <td>-1.716289e+15</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233.660341</td>\n",
       "      <td>5.176621</td>\n",
       "      <td>0.854139</td>\n",
       "      <td>0.973795</td>\n",
       "      <td>-316.718636</td>\n",
       "      <td>-137.235538</td>\n",
       "      <td>-2.803023e+15</td>\n",
       "      <td>-1.677708e+15</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1236.589329</td>\n",
       "      <td>6.362303</td>\n",
       "      <td>0.844816</td>\n",
       "      <td>0.973615</td>\n",
       "      <td>-323.399088</td>\n",
       "      <td>-138.035930</td>\n",
       "      <td>-5.624051e+15</td>\n",
       "      <td>-1.652899e+15</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>285.546735</td>\n",
       "      <td>1.645550</td>\n",
       "      <td>0.784114</td>\n",
       "      <td>0.977032</td>\n",
       "      <td>-404.786024</td>\n",
       "      <td>-126.878500</td>\n",
       "      <td>-3.922569e+15</td>\n",
       "      <td>-1.042910e+15</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time   test_r2  train_r2  \\\n",
       "0  1221.663679   11.541488  0.824293  0.973771   \n",
       "1  1200.971122    9.686063  0.798486  0.975722   \n",
       "2  1233.660341    5.176621  0.854139  0.973795   \n",
       "3  1236.589329    6.362303  0.844816  0.973615   \n",
       "4   285.546735    1.645550  0.784114  0.977032   \n",
       "\n",
       "   test_neg_root_mean_squared_error  train_neg_root_mean_squared_error  \\\n",
       "0                       -357.268651                        -136.370194   \n",
       "1                       -379.701082                        -131.454077   \n",
       "2                       -316.718636                        -137.235538   \n",
       "3                       -323.399088                        -138.035930   \n",
       "4                       -404.786024                        -126.878500   \n",
       "\n",
       "   test_neg_mean_absolute_percentage_error  \\\n",
       "0                            -4.652190e+15   \n",
       "1                            -5.023980e+15   \n",
       "2                            -2.803023e+15   \n",
       "3                            -5.624051e+15   \n",
       "4                            -3.922569e+15   \n",
       "\n",
       "   train_neg_mean_absolute_percentage_error  test_neg_median_absolute_error  \\\n",
       "0                             -1.715361e+15                            -0.0   \n",
       "1                             -1.716289e+15                            -0.0   \n",
       "2                             -1.677708e+15                            -0.0   \n",
       "3                             -1.652899e+15                            -0.0   \n",
       "4                             -1.042910e+15                            -0.0   \n",
       "\n",
       "   train_neg_median_absolute_error  \n",
       "0                             -0.0  \n",
       "1                             -0.0  \n",
       "2                             -0.0  \n",
       "3                             -0.0  \n",
       "4                             -0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline with scaler and model\n",
    "rf_pipeline_built_up = Pipeline([('scaler', StandardScaler()), ('model', RandomForestRegressor(random_state=random_state, n_jobs=4))])\n",
    "\n",
    "# Cross validate the pipeline\n",
    "if not os.path.exists(IMPUTER_MODEL_DIR / 'cv_results_rf_built_up.joblib'):\n",
    "    cv_results_built_up = cross_validation_with_pipeline(rf_pipeline_built_up, X_train, y_train, 'regression')\n",
    "    joblib.dump(cv_results_built_up, IMPUTER_MODEL_DIR / 'cv_results_rf_built_up.joblib')\n",
    "else:\n",
    "    cv_results_built_up = joblib.load(IMPUTER_MODEL_DIR / 'cv_results_rf_built_up.joblib')\n",
    "\n",
    "pd.DataFrame(cv_results_built_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation using random forest took 55m35s. The results wasn't that great, with substantial RMSE and high MAPE. But it performed well on median-based metrics: median absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_percentage_error</th>\n",
       "      <th>train_neg_mean_absolute_percentage_error</th>\n",
       "      <th>test_neg_median_absolute_error</th>\n",
       "      <th>train_neg_median_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115.349414</td>\n",
       "      <td>842.074621</td>\n",
       "      <td>0.728349</td>\n",
       "      <td>0.807001</td>\n",
       "      <td>-444.228462</td>\n",
       "      <td>-369.920969</td>\n",
       "      <td>-3.509313e+15</td>\n",
       "      <td>-3.596327e+15</td>\n",
       "      <td>-65.8</td>\n",
       "      <td>-51.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.173904</td>\n",
       "      <td>835.366826</td>\n",
       "      <td>0.670352</td>\n",
       "      <td>0.815942</td>\n",
       "      <td>-485.639491</td>\n",
       "      <td>-361.949470</td>\n",
       "      <td>-4.940215e+15</td>\n",
       "      <td>-3.815043e+15</td>\n",
       "      <td>-66.6</td>\n",
       "      <td>-51.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115.667840</td>\n",
       "      <td>844.578770</td>\n",
       "      <td>0.728067</td>\n",
       "      <td>0.805778</td>\n",
       "      <td>-432.449172</td>\n",
       "      <td>-373.617202</td>\n",
       "      <td>-4.629208e+15</td>\n",
       "      <td>-4.027341e+15</td>\n",
       "      <td>-65.7</td>\n",
       "      <td>-51.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114.721992</td>\n",
       "      <td>863.657962</td>\n",
       "      <td>0.714709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-438.488940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.069854e+15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.214992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fit_time  score_time   test_r2  train_r2  \\\n",
       "0  115.349414  842.074621  0.728349  0.807001   \n",
       "1   67.173904  835.366826  0.670352  0.815942   \n",
       "2  115.667840  844.578770  0.728067  0.805778   \n",
       "3  114.721992  863.657962  0.714709       NaN   \n",
       "4   17.214992    0.000000       NaN       NaN   \n",
       "\n",
       "   test_neg_root_mean_squared_error  train_neg_root_mean_squared_error  \\\n",
       "0                       -444.228462                        -369.920969   \n",
       "1                       -485.639491                        -361.949470   \n",
       "2                       -432.449172                        -373.617202   \n",
       "3                       -438.488940                                NaN   \n",
       "4                               NaN                                NaN   \n",
       "\n",
       "   test_neg_mean_absolute_percentage_error  \\\n",
       "0                            -3.509313e+15   \n",
       "1                            -4.940215e+15   \n",
       "2                            -4.629208e+15   \n",
       "3                            -7.069854e+15   \n",
       "4                                      NaN   \n",
       "\n",
       "   train_neg_mean_absolute_percentage_error  test_neg_median_absolute_error  \\\n",
       "0                             -3.596327e+15                           -65.8   \n",
       "1                             -3.815043e+15                           -66.6   \n",
       "2                             -4.027341e+15                           -65.7   \n",
       "3                                       NaN                           -66.0   \n",
       "4                                       NaN                             NaN   \n",
       "\n",
       "   train_neg_median_absolute_error  \n",
       "0                            -51.4  \n",
       "1                            -51.6  \n",
       "2                            -51.4  \n",
       "3                              NaN  \n",
       "4                              NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline with scaler and model\n",
    "knn_pipeline_built_up = Pipeline([('scaler', StandardScaler()), ('model', KNeighborsRegressor(n_jobs=4))])\n",
    "\n",
    "# Cross validate the pipeline\n",
    "if not os.path.exists(IMPUTER_MODEL_DIR / 'cv_results_knn_built_up.joblib'):\n",
    "    cv_results_built_up = cross_validation_with_pipeline(knn_pipeline_built_up, X_train, y_train, 'regression')\n",
    "    joblib.dump(cv_results_built_up, IMPUTER_MODEL_DIR / 'cv_results_knn_built_up.joblib')\n",
    "else:\n",
    "    cv_results_built_up = joblib.load(IMPUTER_MODEL_DIR / 'cv_results_knn_built_up.joblib')\n",
    "\n",
    "pd.DataFrame(cv_results_built_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation using KNN took around 148m4s, and then failed at the fourth fold due to insufficient memory. Looking at the results, KNN performed worst then random forest, with higher RMSE, MAPE and median absolute error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check model performance on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(pipeline: Pipeline, X_train: np.ndarray, y_train: np.ndarray, X_val: np.ndarray, y_val: np.ndarray, task: str):\n",
    "\n",
    "    try:\n",
    "        y_val_pred = pipeline.predict(X_val)\n",
    "    except NotFittedError:\n",
    "        print('Pipeline not fitted. Start training...')\n",
    "        pipeline = pipeline.fit(X_train, y_train)\n",
    "        y_val_pred = pipeline.predict(X_val)\n",
    "\n",
    "    print(\"Results for validation set:\")\n",
    "    if task == 'regression':\n",
    "        print(f\"R2 score: {r2_score(y_val, y_val_pred)}\")\n",
    "        print(f\"RMSE score: {sqrt(mean_squared_error(y_val, y_val_pred))}\")\n",
    "        print(f\"MAPE score: {mean_absolute_percentage_error(y_val, y_val_pred)}\")\n",
    "        print(f\"MAE score: {mean_absolute_error(y_val, y_val_pred)}\")\n",
    "        print(f\"Median AE score: {median_absolute_error(y_val, y_val_pred)}\")\n",
    "    elif task == 'classification':\n",
    "        print(f\"Accuracy score: {accuracy_score(y_val, y_val_pred)}\")\n",
    "        print(f\"Balanced accuracy score: {balanced_accuracy_score(y_val, y_val_pred)}\")\n",
    "        print(f\"Macro F1 score: {f1_score(y_val, y_val_pred, average='macro')}\")\n",
    "        print(f\"Weighted F1 score: {f1_score(y_val, y_val_pred, average='weighted')}\")\n",
    "        print(f\"Macro precision score: {precision_score(y_val, y_val_pred, average='macro')}\")\n",
    "        print(f\"Weighted precision score: {precision_score(y_val, y_val_pred, average='weighted')}\")\n",
    "        print(f\"Macro recall score: {recall_score(y_val, y_val_pred, average='macro')}\")\n",
    "        print(f\"Weighted recall score: {recall_score(y_val, y_val_pred, average='weighted')}\")\n",
    "        print(f\"Macro ROC AUC score: {roc_auc_score(y_val, y_val_pred, average='macro', multi_class='ovr')}\")\n",
    "        print(f\"Weighted ROC AUC score: {roc_auc_score(y_val, y_val_pred, average='weighted', multi_class='ovr')}\")\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for validation set:\n",
      "R2 score: 0.8080609693884588\n",
      "RMSE score: 381.9099647033172\n",
      "MAPE score: 3890573305511410.5\n",
      "MAE score: 63.87615023388515\n",
      "Median AE score: 0.0\n"
     ]
    }
   ],
   "source": [
    "model_path = IMPUTER_MODEL_DIR / 'rf_pipeline_built_up.joblib'\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    rf_pipeline_built_up = validate_model(rf_pipeline_built_up, X_train, y_train, X_val, y_val, 'regression')\n",
    "    joblib.dump(rf_pipeline_built_up, model_path, compress=('lzma', 9))\n",
    "else:\n",
    "    rf_pipeline_built_up = joblib.load(model_path)\n",
    "    _ = validate_model(rf_pipeline_built_up, X_train, y_train, X_val, y_val, 'regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest took 6m8s for training on training data and prediction of validation data, and 2.5 second for loading fitted model and predicting validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for validation set:\n",
      "R2 score: 0.6834473458154234\n",
      "RMSE score: 490.45856274893976\n",
      "MAPE score: 4185698477203167.0\n",
      "MAE score: 158.56516414749206\n",
      "Median AE score: 63.200000000000045\n"
     ]
    }
   ],
   "source": [
    "model_path = IMPUTER_MODEL_DIR / 'knn_pipeline_built_up.joblib'\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    knn_pipeline_built_up = validate_model(knn_pipeline_built_up, X_train, y_train, X_val, y_val, 'regression')\n",
    "    joblib.dump(knn_pipeline_built_up, model_path, compress=('lzma', 5))\n",
    "else:\n",
    "    knn_pipeline_built_up = joblib.load(model_path)\n",
    "    _ = validate_model(knn_pipeline_built_up, X_train, y_train, X_val, y_val, 'regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN took 4m39s for training on training data and prediction of validation data, and 4m54s for loading fitted model and predicting validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing random forest and KNN on both cross validation and validation data, random forest performed better than KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impute `built_up` using the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_with_model(pipeline: Pipeline, df_train: pd.DataFrame, df_test: pd.DataFrame, target: str):\n",
    "\n",
    "    y_test_pred = pipeline.predict(df_test)\n",
    "\n",
    "    df_test[target] = y_test_pred\n",
    "    df_imputed = pd.concat([df_train, df_test])\n",
    "\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 265270 entries, 252 to 75120\n",
      "Columns: 1904 entries, township_BANDAR BARU SRI PETALING to day\n",
      "dtypes: float64(5), int32(3), int64(1896)\n",
      "memory usage: 3.8 GB\n"
     ]
    }
   ],
   "source": [
    "df_test = df_test.drop(columns=[target]).dropna()\n",
    "df_transactions_built_up_imputed = impute_with_model(rf_pipeline_built_up, df_train, df_test, target='built_up')\n",
    "df_transactions_built_up_imputed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Join the imputed `built_up` data with the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 265270 entries, 252 to 75120\n",
      "Columns: 1905 entries, township_BANDAR BARU SRI PETALING to rooms\n",
      "dtypes: float64(6), int32(3), int64(1896)\n",
      "memory usage: 3.8 GB\n"
     ]
    }
   ],
   "source": [
    "df_transactions_built_up_imputed = df_transactions_built_up_imputed.join(df_transactions_encoded['rooms'])\n",
    "df_transactions_built_up_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rooms 29217\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in all columns\n",
    "for column in df_transactions_built_up_imputed.columns:\n",
    "    isna_count = df_transactions_built_up_imputed[column].isna().sum()\n",
    "    if isna_count > 0:\n",
    "        print(column, isna_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing `rooms`\n",
    "\n",
    "The steps are:\n",
    "1. Remove `rooms` with less than 5 samples so that CV can be performed\n",
    "2. Cross validate for `rooms` using:\n",
    "    - Random forest imputation\n",
    "    - KNN imputation\n",
    "3. Use the better model to impute `rooms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'rooms'\n",
    "\n",
    "# Split the dataset into train and test, where train are the data with labels and test are the data without labels\n",
    "df_train = df_transactions_built_up_imputed[df_transactions_built_up_imputed[target].notna()]\n",
    "df_train = df_train.groupby(target).filter(lambda x : len(x) > 5).dropna() # Drop rooms with less than 5 samples so that CV can be performed\n",
    "df_test = df_transactions_built_up_imputed[df_transactions_built_up_imputed[target].isna()]\n",
    "\n",
    "# Split the train dataset into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train.drop(columns=[target]), df_train[target], test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross validation for `built_up` using various techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "2 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 370, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 950, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 918, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 837, in fit\n",
      "    return self.partial_fit(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 958, in partial_fit\n",
      "    self.mean_, self.var_, self.n_samples_seen_ = _incremental_mean_and_var(\n",
      "                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\utils\\extmath.py\", line 1057, in _incremental_mean_and_var\n",
      "    temp = X - T\n",
      "           ~~^~~\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.14 GiB for an array with shape (151044, 1904) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 370, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 950, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 918, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 1004, in transform\n",
      "    X = self._validate_data(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 604, in _validate_data\n",
      "    out = check_array(X, input_name=\"X\", **check_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 987, in check_array\n",
      "    if np.may_share_memory(array, array_orig):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2083, in __array__\n",
      "    values = self._values\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\pandas\\core\\frame.py\", line 1049, in _values\n",
      "    return ensure_wrapped_if_datetimelike(self.values)\n",
      "                                          ^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\pandas\\core\\frame.py\", line 12284, in values\n",
      "    return self._mgr.as_array()\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1656, in as_array\n",
      "    arr = self._interleave(dtype=dtype, na_value=na_value)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1689, in _interleave\n",
      "    result = np.empty(self.shape, dtype=dtype)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.14 GiB for an array with shape (1904, 151045) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_percentage_error</th>\n",
       "      <th>train_neg_mean_absolute_percentage_error</th>\n",
       "      <th>test_neg_median_absolute_error</th>\n",
       "      <th>train_neg_median_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.685828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251.693279</td>\n",
       "      <td>10.347663</td>\n",
       "      <td>0.429146</td>\n",
       "      <td>0.996970</td>\n",
       "      <td>-0.734488</td>\n",
       "      <td>-0.052480</td>\n",
       "      <td>-1.645869e+13</td>\n",
       "      <td>-1.788977e+11</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.241544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>241.388860</td>\n",
       "      <td>6.027060</td>\n",
       "      <td>0.456886</td>\n",
       "      <td>0.997788</td>\n",
       "      <td>-0.696532</td>\n",
       "      <td>-0.045157</td>\n",
       "      <td>-1.788988e+13</td>\n",
       "      <td>-1.192651e+11</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>232.804780</td>\n",
       "      <td>6.727474</td>\n",
       "      <td>0.506015</td>\n",
       "      <td>0.997310</td>\n",
       "      <td>-0.666395</td>\n",
       "      <td>-0.049760</td>\n",
       "      <td>-1.908254e+13</td>\n",
       "      <td>-2.981628e+10</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fit_time  score_time   test_r2  train_r2  \\\n",
       "0   28.685828    0.000000       NaN       NaN   \n",
       "1  251.693279   10.347663  0.429146  0.996970   \n",
       "2   51.241544    0.000000       NaN       NaN   \n",
       "3  241.388860    6.027060  0.456886  0.997788   \n",
       "4  232.804780    6.727474  0.506015  0.997310   \n",
       "\n",
       "   test_neg_root_mean_squared_error  train_neg_root_mean_squared_error  \\\n",
       "0                               NaN                                NaN   \n",
       "1                         -0.734488                          -0.052480   \n",
       "2                               NaN                                NaN   \n",
       "3                         -0.696532                          -0.045157   \n",
       "4                         -0.666395                          -0.049760   \n",
       "\n",
       "   test_neg_mean_absolute_percentage_error  \\\n",
       "0                                      NaN   \n",
       "1                            -1.645869e+13   \n",
       "2                                      NaN   \n",
       "3                            -1.788988e+13   \n",
       "4                            -1.908254e+13   \n",
       "\n",
       "   train_neg_mean_absolute_percentage_error  test_neg_median_absolute_error  \\\n",
       "0                                       NaN                             NaN   \n",
       "1                             -1.788977e+11                            -0.0   \n",
       "2                                       NaN                             NaN   \n",
       "3                             -1.192651e+11                            -0.0   \n",
       "4                             -2.981628e+10                            -0.0   \n",
       "\n",
       "   train_neg_median_absolute_error  \n",
       "0                              NaN  \n",
       "1                             -0.0  \n",
       "2                              NaN  \n",
       "3                             -0.0  \n",
       "4                             -0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline with scaler and model\n",
    "rf_pipeline_rooms = Pipeline([('scaler', StandardScaler()), ('model', RandomForestClassifier(random_state=random_state, n_jobs=4))])\n",
    "\n",
    "# Cross validate the pipeline\n",
    "if not os.path.exists(IMPUTER_MODEL_DIR / 'cv_results_rf_rooms.joblib'):\n",
    "    cv_results_rooms = cross_validation_with_pipeline(rf_pipeline_rooms, X_train, y_train, 'regression')\n",
    "    joblib.dump(cv_results_rooms, IMPUTER_MODEL_DIR / 'cv_results_rf_rooms.joblib')\n",
    "else:\n",
    "    cv_results_rooms = joblib.load(IMPUTER_MODEL_DIR / 'cv_results_rf_rooms.joblib')\n",
    "\n",
    "pd.DataFrame(cv_results_rooms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation took 8m5s to complete. There are classes which has only one transactions, therefore the rooms with less than 5 counts were not included for cross validation.\n",
    "\n",
    "From the cross validation results, the model overfits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "2 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 370, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 950, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 918, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 1004, in transform\n",
      "    X = self._validate_data(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 604, in _validate_data\n",
      "    out = check_array(X, input_name=\"X\", **check_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 987, in check_array\n",
      "    if np.may_share_memory(array, array_orig):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2083, in __array__\n",
      "    values = self._values\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\pandas\\core\\frame.py\", line 1049, in _values\n",
      "    return ensure_wrapped_if_datetimelike(self.values)\n",
      "                                          ^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\pandas\\core\\frame.py\", line 12284, in values\n",
      "    return self._mgr.as_array()\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1656, in as_array\n",
      "    arr = self._interleave(dtype=dtype, na_value=na_value)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1689, in _interleave\n",
      "    result = np.empty(self.shape, dtype=dtype)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.14 GiB for an array with shape (1904, 151045) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 370, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 950, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 918, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 837, in fit\n",
      "    return self.partial_fit(X, y, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 958, in partial_fit\n",
      "    self.mean_, self.var_, self.n_samples_seen_ = _incremental_mean_and_var(\n",
      "                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\utils\\extmath.py\", line 1057, in _incremental_mean_and_var\n",
      "    temp = X - T\n",
      "           ~~^~~\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.14 GiB for an array with shape (151045, 1904) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_percentage_error</th>\n",
       "      <th>train_neg_mean_absolute_percentage_error</th>\n",
       "      <th>test_neg_median_absolute_error</th>\n",
       "      <th>train_neg_median_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.168992</td>\n",
       "      <td>423.701747</td>\n",
       "      <td>0.382646</td>\n",
       "      <td>0.511510</td>\n",
       "      <td>-0.745020</td>\n",
       "      <td>-0.670505</td>\n",
       "      <td>-1.872425e+13</td>\n",
       "      <td>-1.267200e+13</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.414525</td>\n",
       "      <td>406.607987</td>\n",
       "      <td>0.375650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.768132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.443117e+13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.702898</td>\n",
       "      <td>425.574222</td>\n",
       "      <td>0.360377</td>\n",
       "      <td>0.472983</td>\n",
       "      <td>-0.777078</td>\n",
       "      <td>-0.692177</td>\n",
       "      <td>-1.526604e+13</td>\n",
       "      <td>-1.386457e+13</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.375724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.482107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time   test_r2  train_r2  \\\n",
       "0  47.168992  423.701747  0.382646  0.511510   \n",
       "1  98.414525  406.607987  0.375650       NaN   \n",
       "2  51.702898  425.574222  0.360377  0.472983   \n",
       "3  35.375724    0.000000       NaN       NaN   \n",
       "4  59.482107    0.000000       NaN       NaN   \n",
       "\n",
       "   test_neg_root_mean_squared_error  train_neg_root_mean_squared_error  \\\n",
       "0                         -0.745020                          -0.670505   \n",
       "1                         -0.768132                                NaN   \n",
       "2                         -0.777078                          -0.692177   \n",
       "3                               NaN                                NaN   \n",
       "4                               NaN                                NaN   \n",
       "\n",
       "   test_neg_mean_absolute_percentage_error  \\\n",
       "0                            -1.872425e+13   \n",
       "1                            -1.443117e+13   \n",
       "2                            -1.526604e+13   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "\n",
       "   train_neg_mean_absolute_percentage_error  test_neg_median_absolute_error  \\\n",
       "0                             -1.267200e+13                            -0.0   \n",
       "1                                       NaN                            -0.0   \n",
       "2                             -1.386457e+13                            -0.0   \n",
       "3                                       NaN                             NaN   \n",
       "4                                       NaN                             NaN   \n",
       "\n",
       "   train_neg_median_absolute_error  \n",
       "0                             -0.0  \n",
       "1                              NaN  \n",
       "2                             -0.0  \n",
       "3                              NaN  \n",
       "4                              NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline with scaler and model\n",
    "knn_pipeline_rooms = Pipeline([('scaler', StandardScaler()), ('model', KNeighborsClassifier(n_jobs=4))])\n",
    "\n",
    "# Cross validate the pipeline\n",
    "if not os.path.exists(IMPUTER_MODEL_DIR / 'cv_results_knn_rooms.joblib'):\n",
    "    cv_results_rooms = cross_validation_with_pipeline(knn_pipeline_rooms, X_train, y_train, 'regression')\n",
    "    joblib.dump(cv_results_rooms, IMPUTER_MODEL_DIR / 'cv_results_knn_rooms.joblib')\n",
    "else:\n",
    "    cv_results_rooms = joblib.load(IMPUTER_MODEL_DIR / 'cv_results_knn_rooms.joblib')\n",
    "\n",
    "pd.DataFrame(cv_results_rooms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check model performance on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for validation set:\n",
      "Accuracy score: 0.8350705478581416\n",
      "Balanced accuracy score: 0.33657015622976827\n",
      "Macro F1 score: 0.376981223121691\n",
      "Weighted F1 score: 0.831617850387697\n",
      "Macro precision score: 0.4883131102823608\n",
      "Weighted precision score: 0.831007007869572\n",
      "Macro recall score: 0.33657015622976827\n",
      "Weighted recall score: 0.8350705478581416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Repos\\GitHub\\time-series-house-price-forecasting\\notebooks\\Transactions - 04 Data Cleaning 2.ipynb Cell 37\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/GitHub/time-series-house-price-forecasting/notebooks/Transactions%20-%2004%20Data%20Cleaning%202.ipynb#Y204sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_path \u001b[39m=\u001b[39m IMPUTER_MODEL_DIR \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrf_pipeline_rooms.joblib\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/GitHub/time-series-house-price-forecasting/notebooks/Transactions%20-%2004%20Data%20Cleaning%202.ipynb#Y204sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(model_path):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Repos/GitHub/time-series-house-price-forecasting/notebooks/Transactions%20-%2004%20Data%20Cleaning%202.ipynb#Y204sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     rf_pipeline_rooms \u001b[39m=\u001b[39m validate_model(rf_pipeline_rooms, X_train, y_train, X_val, y_val, \u001b[39m'\u001b[39;49m\u001b[39mclassification\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/GitHub/time-series-house-price-forecasting/notebooks/Transactions%20-%2004%20Data%20Cleaning%202.ipynb#Y204sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     joblib\u001b[39m.\u001b[39mdump(rf_pipeline_rooms, model_path, compress\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mlzma\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m9\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/GitHub/time-series-house-price-forecasting/notebooks/Transactions%20-%2004%20Data%20Cleaning%202.ipynb#Y204sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32md:\\Repos\\GitHub\\time-series-house-price-forecasting\\notebooks\\Transactions - 04 Data Cleaning 2.ipynb Cell 37\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/GitHub/time-series-house-price-forecasting/notebooks/Transactions%20-%2004%20Data%20Cleaning%202.ipynb#Y204sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMacro recall score: \u001b[39m\u001b[39m{\u001b[39;00mrecall_score(y_val,\u001b[39m \u001b[39my_val_pred,\u001b[39m \u001b[39maverage\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/GitHub/time-series-house-price-forecasting/notebooks/Transactions%20-%2004%20Data%20Cleaning%202.ipynb#Y204sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWeighted recall score: \u001b[39m\u001b[39m{\u001b[39;00mrecall_score(y_val,\u001b[39m \u001b[39my_val_pred,\u001b[39m \u001b[39maverage\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Repos/GitHub/time-series-house-price-forecasting/notebooks/Transactions%20-%2004%20Data%20Cleaning%202.ipynb#Y204sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMacro ROC AUC score: \u001b[39m\u001b[39m{\u001b[39;00mroc_auc_score(y_val,\u001b[39m \u001b[39;49my_val_pred,\u001b[39m \u001b[39;49maverage\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmacro\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m \u001b[39;49mmulti_class\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39movr\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/GitHub/time-series-house-price-forecasting/notebooks/Transactions%20-%2004%20Data%20Cleaning%202.ipynb#Y204sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWeighted ROC AUC score: \u001b[39m\u001b[39m{\u001b[39;00mroc_auc_score(y_val,\u001b[39m \u001b[39my_val_pred,\u001b[39m \u001b[39maverage\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m \u001b[39mmulti_class\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39movr\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/GitHub/time-series-house-price-forecasting/notebooks/Transactions%20-%2004%20Data%20Cleaning%202.ipynb#Y204sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pipeline\n",
      "File \u001b[1;32md:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32md:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:620\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    618\u001b[0m     \u001b[39mif\u001b[39;00m multi_class \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    619\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmulti_class must be in (\u001b[39m\u001b[39m'\u001b[39m\u001b[39movo\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39movr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 620\u001b[0m     \u001b[39mreturn\u001b[39;00m _multiclass_roc_auc_score(\n\u001b[0;32m    621\u001b[0m         y_true, y_score, labels, multi_class, average, sample_weight\n\u001b[0;32m    622\u001b[0m     )\n\u001b[0;32m    623\u001b[0m \u001b[39melif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    624\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y_true)\n",
      "File \u001b[1;32md:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:692\u001b[0m, in \u001b[0;36m_multiclass_roc_auc_score\u001b[1;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Multiclass roc auc score.\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \n\u001b[0;32m    648\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    689\u001b[0m \n\u001b[0;32m    690\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[39m# validation of the input y_score\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mallclose(\u001b[39m1\u001b[39m, y_score\u001b[39m.\u001b[39;49msum(axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)):\n\u001b[0;32m    693\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    694\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTarget scores need to be probabilities for multiclass \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    695\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mroc_auc, i.e. they should sum up to 1.0 over classes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    696\u001b[0m     )\n\u001b[0;32m    698\u001b[0m \u001b[39m# validation for multiclass parameter specifications\u001b[39;00m\n",
      "File \u001b[1;32md:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\numpy\\core\\_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m          initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "model_path = IMPUTER_MODEL_DIR / 'rf_pipeline_rooms.joblib'\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    rf_pipeline_rooms = validate_model(rf_pipeline_rooms, X_train, y_train, X_val, y_val, 'classification')\n",
    "    joblib.dump(rf_pipeline_rooms, model_path, compress=('lzma', 9))\n",
    "else:\n",
    "    rf_pipeline_rooms = joblib.load(model_path)\n",
    "    _ = validate_model(rf_pipeline_rooms, X_train, y_train, X_val, y_val, 'classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline took 2m27s to train and predict. However, the results were not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for validation set:\n",
      "R2 score: 0.5527093748549827\n",
      "RMSE score: 0.5689410437602002\n",
      "MAPE score: 15647437373178.346\n",
      "Median AE score: 0.0\n"
     ]
    }
   ],
   "source": [
    "model_path = IMPUTER_MODEL_DIR / 'knn_pipeline_rooms.joblib'\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    knn_pipeline_rooms = validate_model(knn_pipeline_rooms, X_train, y_train, X_val, y_val, 'classification')\n",
    "    joblib.dump(knn_pipeline_rooms, model_path, compress=('lzma', 5))\n",
    "else:\n",
    "    knn_pipeline_rooms = joblib.load(model_path)\n",
    "    _ = validate_model(knn_pipeline_rooms, X_train, y_train, X_val, y_val, 'classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline took 2m27s to train and predict. However, the results were not good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impute `rooms` using the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 265225 entries, 253 to 76762\n",
      "Columns: 1905 entries, township_BANDAR BARU SRI PETALING to rooms\n",
      "dtypes: float64(6), int32(3), int64(1896)\n",
      "memory usage: 3.8 GB\n"
     ]
    }
   ],
   "source": [
    "df_test = df_test.drop(columns=[target]).dropna()\n",
    "df_transactions_rooms_imputed = impute_with_model(rf_pipeline_rooms, df_train, df_test, target='rooms')\n",
    "df_transactions_rooms_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_transactions_rooms_imputed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Repos\\GitHub\\time-series-house-price-forecasting\\notebooks\\Transactions - 04 Data Cleaning 2.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Repos/GitHub/time-series-house-price-forecasting/notebooks/Transactions%20-%2004%20Data%20Cleaning%202.ipynb#Y213sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m df_transactions_rooms_imputed\u001b[39m.\u001b[39mcolumns:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/GitHub/time-series-house-price-forecasting/notebooks/Transactions%20-%2004%20Data%20Cleaning%202.ipynb#Y213sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     isna_count \u001b[39m=\u001b[39m df_transactions_rooms_imputed[column]\u001b[39m.\u001b[39misna()\u001b[39m.\u001b[39msum()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/GitHub/time-series-house-price-forecasting/notebooks/Transactions%20-%2004%20Data%20Cleaning%202.ipynb#Y213sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mif\u001b[39;00m isna_count \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_transactions_rooms_imputed' is not defined"
     ]
    }
   ],
   "source": [
    "for column in df_transactions_rooms_imputed.columns:\n",
    "    isna_count = df_transactions_rooms_imputed[column].isna().sum()\n",
    "    if isna_count > 0:\n",
    "        print(column, isna_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

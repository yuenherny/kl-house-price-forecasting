{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning: Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Union\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import skops.io as sio\n",
    "\n",
    "from helpers import (\n",
    "    cross_validation_with_pipeline, train_and_validate_model, validate_impute\n",
    ")\n",
    "from helpers import (\n",
    "    CACHE_DATA_DIR, TRANSFORMED_DATA_DIR, IMPUTER_MODEL_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>township_BANDAR BARU SRI PETALING</th>\n",
       "      <th>township_TAMAN TUN DR ISMAIL</th>\n",
       "      <th>township_DAMANSARA HEIGHTS (BUKIT DAMANSARA)</th>\n",
       "      <th>township_TAMAN BUKIT MALURI</th>\n",
       "      <th>township_KEPONG BARU</th>\n",
       "      <th>township_OVERSEAS UNION GARDEN</th>\n",
       "      <th>township_HAPPY GARDEN</th>\n",
       "      <th>township_TAMAN MIDAH</th>\n",
       "      <th>township_ALAM DAMAI</th>\n",
       "      <th>township_TAMAN SRI SINAR</th>\n",
       "      <th>...</th>\n",
       "      <th>tenure_FREEHOLD</th>\n",
       "      <th>floors</th>\n",
       "      <th>rooms</th>\n",
       "      <th>land_area</th>\n",
       "      <th>built_up</th>\n",
       "      <th>price_psf</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2196.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>342.0</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>753.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>398.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3197.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>753.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>531.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4801.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265265</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>1990</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265266</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>218025.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265268</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>235000.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265269</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>518296.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265270 rows × 1905 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        township_BANDAR BARU SRI PETALING  township_TAMAN TUN DR ISMAIL  \\\n",
       "0                                       1                             0   \n",
       "1                                       1                             0   \n",
       "2                                       1                             0   \n",
       "3                                       1                             0   \n",
       "4                                       1                             0   \n",
       "...                                   ...                           ...   \n",
       "265265                                  0                             0   \n",
       "265266                                  0                             0   \n",
       "265267                                  0                             0   \n",
       "265268                                  0                             0   \n",
       "265269                                  0                             0   \n",
       "\n",
       "        township_DAMANSARA HEIGHTS (BUKIT DAMANSARA)  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "...                                              ...   \n",
       "265265                                             0   \n",
       "265266                                             0   \n",
       "265267                                             0   \n",
       "265268                                             0   \n",
       "265269                                             0   \n",
       "\n",
       "        township_TAMAN BUKIT MALURI  township_KEPONG BARU  \\\n",
       "0                                 0                     0   \n",
       "1                                 0                     0   \n",
       "2                                 0                     0   \n",
       "3                                 0                     0   \n",
       "4                                 0                     0   \n",
       "...                             ...                   ...   \n",
       "265265                            0                     0   \n",
       "265266                            0                     0   \n",
       "265267                            0                     0   \n",
       "265268                            0                     0   \n",
       "265269                            0                     0   \n",
       "\n",
       "        township_OVERSEAS UNION GARDEN  township_HAPPY GARDEN  \\\n",
       "0                                    0                      0   \n",
       "1                                    0                      0   \n",
       "2                                    0                      0   \n",
       "3                                    0                      0   \n",
       "4                                    0                      0   \n",
       "...                                ...                    ...   \n",
       "265265                               0                      0   \n",
       "265266                               0                      0   \n",
       "265267                               0                      0   \n",
       "265268                               0                      0   \n",
       "265269                               0                      0   \n",
       "\n",
       "        township_TAMAN MIDAH  township_ALAM DAMAI  township_TAMAN SRI SINAR  \\\n",
       "0                          0                    0                         0   \n",
       "1                          0                    0                         0   \n",
       "2                          0                    0                         0   \n",
       "3                          0                    0                         0   \n",
       "4                          0                    0                         0   \n",
       "...                      ...                  ...                       ...   \n",
       "265265                     0                    0                         0   \n",
       "265266                     0                    0                         0   \n",
       "265267                     0                    0                         0   \n",
       "265268                     0                    0                         0   \n",
       "265269                     0                    0                         0   \n",
       "\n",
       "        ...  tenure_FREEHOLD  floors  rooms  land_area  built_up  price_psf  \\\n",
       "0       ...                0     1.0    NaN     2196.0       NaN      342.0   \n",
       "1       ...                0     2.0    NaN      753.0       NaN      398.0   \n",
       "2       ...                0     2.5    NaN     3197.0       NaN      188.0   \n",
       "3       ...                0     2.0    NaN      753.0       NaN      531.0   \n",
       "4       ...                0     2.5    NaN     4801.0       NaN      250.0   \n",
       "...     ...              ...     ...    ...        ...       ...        ...   \n",
       "265265  ...                0     1.0    2.0      493.0     493.0       71.0   \n",
       "265266  ...                1     1.0    3.0     1454.0    1454.0      150.0   \n",
       "265267  ...                1     1.0    3.0      593.0     593.0      194.0   \n",
       "265268  ...                0     1.0    2.0     1193.0    1193.0      197.0   \n",
       "265269  ...                0     1.0    3.0     1927.0    1927.0      269.0   \n",
       "\n",
       "            price  year  month  day  \n",
       "0        750000.0  2023      6    9  \n",
       "1        300000.0  2023      6    1  \n",
       "2        600000.0  2023      5   29  \n",
       "3        400000.0  2023      5   25  \n",
       "4       1200000.0  2023      5   22  \n",
       "...           ...   ...    ...  ...  \n",
       "265265    35000.0  1990     11   13  \n",
       "265266   218025.0  2005      1   10  \n",
       "265267   115000.0  2008      2   25  \n",
       "265268   235000.0  2009      8   10  \n",
       "265269   518296.0  1995      8   18  \n",
       "\n",
       "[265270 rows x 1905 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_encoded = pd.read_parquet(TRANSFORMED_DATA_DIR / 'transactions_KL_ckpt4_encoded.parquet')\n",
    "df_transactions_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 265270 entries, 0 to 265269\n",
      "Columns: 1905 entries, township_BANDAR BARU SRI PETALING to day\n",
      "dtypes: float64(6), int32(3), int64(1896)\n",
      "memory usage: 3.8 GB\n"
     ]
    }
   ],
   "source": [
    "df_transactions_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concluding Remarks from Data Cleaning 1: Recap\n",
    "1. The following data cleaning steps has been performed:\n",
    "    - Removed address column\n",
    "    - Changed fraction to decimal\n",
    "    - Removed commas in numerical values\n",
    "    - Removed units in numerical values\n",
    "    - Removed exact duplicates\n",
    "    - Removed outliers using HDBSCAN, based on:\n",
    "        - Continuous variables: `land_area`, `built_up`, `price_psf` (3D)\n",
    "        - Ordinal variables: `floors`, `rooms` (2D)\n",
    "2. Investigated missing values in `built_up` and `rooms`\n",
    "    - Investigated correlation and association between features to determine which features to use to impute missing values\n",
    "3. Encoded features for imputation using one hot encoding\n",
    "\n",
    "Next, we should proceed to impute the missing values in `built_up` and `rooms`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values\n",
    "\n",
    "Based on literature, the following imputation methods have been identified:\n",
    "1. Random forest imputation (Jager et al., 2021) for MCAR, MAR and MNAR data in various domain\n",
    "2. Multiple imputation by deterministic regression (Donlen, 2022) for MCAR data in real estate domain\n",
    "3. MissForest (Waljee et al., 2013) for MCAR data in medical domain\n",
    "4. Predictive mean matching, PMM (Heidt, 2019) for MAR data in medical domain\n",
    "5. KNN imputation (Jadhav et al., 2019) for MCAR, MAR and MNAR data in UCI dataset\n",
    "\n",
    "However, when filtered by domain (real estate), only three methods are identified:\n",
    "1. Random forest imputation\n",
    "2. KNN imputation\n",
    "3. Multiple imputation by deterministic regression\n",
    "\n",
    "These are machine learning approaches for imputation, where we treat the features with missing values as target variable and the features without missing values as independent variables. In order to obtain a better overview of the performance of the imputation methods, we use cross validation techniques:\n",
    "1. Split the dataset into train and test, where train are the data with labels and test are the data without labels\n",
    "2. Split the train dataset into train and validation\n",
    "3. Cross validate the train data:\n",
    "    - Create a pipeline with scaler and model\n",
    "    - Run cross validation with scoring\n",
    "    - Output both train and validation scores\n",
    "    - Return the pipeline and cross validation results\n",
    "4. Train and evaluate the model with validation data\n",
    "    - Train the pipeline with train data\n",
    "    - Predict the validation data\n",
    "    - Evaluate the model with validation data\n",
    "5. Evaluate the pipeline with validation data and print out the metrics\n",
    "6. Predict the test data\n",
    "7. Return the imputed dataset and the fitted pipeline\n",
    "\n",
    "References:\n",
    "- Jager et al. (2021): https://www.frontiersin.org/articles/10.3389/fdata.2021.693674/full\n",
    "- Donlen (2022): https://egrove.olemiss.edu/cgi/viewcontent.cgi?article=3744&context=hon_thesis\n",
    "- Waljee et al. (2013): https://bmjopen.bmj.com/content/3/8/e002847.citation-tools\n",
    "- Heidt (2019): https://dc.etsu.edu/cgi/viewcontent.cgi?article=5014&context=etd\n",
    "- Jadhav et al (2019): https://www.tandfonline.com/doi/full/10.1080/08839514.2019.1637138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "Model = Union[RandomForestRegressor, KNeighborsRegressor, RandomForestClassifier, KNeighborsClassifier]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple imputation\n",
    "\n",
    "Scikit-learn has imputers built in, e.g. KNNImputer and IterativeImputer. Moreover, they are a replacement of the `fancyimpute` package, which is no longer maintained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>township_BANDAR BARU SRI PETALING</th>\n",
       "      <th>township_TAMAN TUN DR ISMAIL</th>\n",
       "      <th>township_DAMANSARA HEIGHTS (BUKIT DAMANSARA)</th>\n",
       "      <th>township_TAMAN BUKIT MALURI</th>\n",
       "      <th>township_KEPONG BARU</th>\n",
       "      <th>township_OVERSEAS UNION GARDEN</th>\n",
       "      <th>township_HAPPY GARDEN</th>\n",
       "      <th>township_TAMAN MIDAH</th>\n",
       "      <th>township_ALAM DAMAI</th>\n",
       "      <th>township_TAMAN SRI SINAR</th>\n",
       "      <th>...</th>\n",
       "      <th>tenure_FREEHOLD</th>\n",
       "      <th>floors</th>\n",
       "      <th>rooms</th>\n",
       "      <th>land_area</th>\n",
       "      <th>built_up</th>\n",
       "      <th>price_psf</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.893189</td>\n",
       "      <td>2196.0</td>\n",
       "      <td>1130.011500</td>\n",
       "      <td>342.0</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.079764</td>\n",
       "      <td>753.0</td>\n",
       "      <td>1272.862928</td>\n",
       "      <td>398.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.232031</td>\n",
       "      <td>3197.0</td>\n",
       "      <td>1521.765384</td>\n",
       "      <td>188.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.091576</td>\n",
       "      <td>753.0</td>\n",
       "      <td>1256.558519</td>\n",
       "      <td>531.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.837520</td>\n",
       "      <td>4801.0</td>\n",
       "      <td>2202.912522</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1905 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   township_BANDAR BARU SRI PETALING  township_TAMAN TUN DR ISMAIL  \\\n",
       "0                                1.0                           0.0   \n",
       "1                                1.0                           0.0   \n",
       "2                                1.0                           0.0   \n",
       "3                                1.0                           0.0   \n",
       "4                                1.0                           0.0   \n",
       "\n",
       "   township_DAMANSARA HEIGHTS (BUKIT DAMANSARA)  township_TAMAN BUKIT MALURI  \\\n",
       "0                                           0.0                          0.0   \n",
       "1                                           0.0                          0.0   \n",
       "2                                           0.0                          0.0   \n",
       "3                                           0.0                          0.0   \n",
       "4                                           0.0                          0.0   \n",
       "\n",
       "   township_KEPONG BARU  township_OVERSEAS UNION GARDEN  \\\n",
       "0                   0.0                             0.0   \n",
       "1                   0.0                             0.0   \n",
       "2                   0.0                             0.0   \n",
       "3                   0.0                             0.0   \n",
       "4                   0.0                             0.0   \n",
       "\n",
       "   township_HAPPY GARDEN  township_TAMAN MIDAH  township_ALAM DAMAI  \\\n",
       "0                    0.0                   0.0                  0.0   \n",
       "1                    0.0                   0.0                  0.0   \n",
       "2                    0.0                   0.0                  0.0   \n",
       "3                    0.0                   0.0                  0.0   \n",
       "4                    0.0                   0.0                  0.0   \n",
       "\n",
       "   township_TAMAN SRI SINAR  ...  tenure_FREEHOLD  floors     rooms  \\\n",
       "0                       0.0  ...              0.0     1.0  2.893189   \n",
       "1                       0.0  ...              0.0     2.0  3.079764   \n",
       "2                       0.0  ...              0.0     2.5  3.232031   \n",
       "3                       0.0  ...              0.0     2.0  3.091576   \n",
       "4                       0.0  ...              0.0     2.5  3.837520   \n",
       "\n",
       "   land_area     built_up  price_psf      price    year  month   day  \n",
       "0     2196.0  1130.011500      342.0   750000.0  2023.0    6.0   9.0  \n",
       "1      753.0  1272.862928      398.0   300000.0  2023.0    6.0   1.0  \n",
       "2     3197.0  1521.765384      188.0   600000.0  2023.0    5.0  29.0  \n",
       "3      753.0  1256.558519      531.0   400000.0  2023.0    5.0  25.0  \n",
       "4     4801.0  2202.912522      250.0  1200000.0  2023.0    5.0  22.0  \n",
       "\n",
       "[5 rows x 1905 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = IMPUTER_MODEL_DIR / 'bayesianridge_multi_imputer.joblib'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    bayesianridge_multi_imputer = joblib.load(model_path)\n",
    "else:\n",
    "    bayesianridge_multi_imputer = IterativeImputer(random_state=random_state, initial_strategy='median', skip_complete=True)\n",
    "    bayesianridge_multi_imputer = bayesianridge_multi_imputer.fit(df_transactions_encoded)\n",
    "    joblib.dump(bayesianridge_multi_imputer, model_path, compress=('lzma', 9))\n",
    "\n",
    "df_transactions_bayesianridge_multi_imputed = pd.DataFrame(bayesianridge_multi_imputer.transform(df_transactions_encoded), columns=df_transactions_encoded.columns)\n",
    "df_transactions_bayesianridge_multi_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple imputation with bayesian ridge took 10m41s to train and impute the data. With models ready, imputation took 1m32s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = IMPUTER_MODEL_DIR / 'linreg_multi_imputer.joblib'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    linreg_multi_imputer = joblib.load(model_path)\n",
    "else:\n",
    "    linreg_multi_imputer = IterativeImputer(estimator=LinearRegression(), random_state=random_state, initial_strategy='median', skip_complete=True)\n",
    "    linreg_multi_imputer = linreg_multi_imputer.fit(df_transactions_encoded)\n",
    "    joblib.dump(linreg_multi_imputer, model_path, compress=('lzma', 9))\n",
    "\n",
    "df_transactions_linreg_multi_imputed = pd.DataFrame(linreg_multi_imputer.transform(df_transactions_encoded), columns=df_transactions_encoded.columns)\n",
    "df_transactions_linreg_multi_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>township_BANDAR BARU SRI PETALING</th>\n",
       "      <th>township_TAMAN TUN DR ISMAIL</th>\n",
       "      <th>township_DAMANSARA HEIGHTS (BUKIT DAMANSARA)</th>\n",
       "      <th>township_TAMAN BUKIT MALURI</th>\n",
       "      <th>township_KEPONG BARU</th>\n",
       "      <th>township_OVERSEAS UNION GARDEN</th>\n",
       "      <th>township_HAPPY GARDEN</th>\n",
       "      <th>township_TAMAN MIDAH</th>\n",
       "      <th>township_ALAM DAMAI</th>\n",
       "      <th>township_TAMAN SRI SINAR</th>\n",
       "      <th>...</th>\n",
       "      <th>tenure_FREEHOLD</th>\n",
       "      <th>floors</th>\n",
       "      <th>rooms</th>\n",
       "      <th>land_area</th>\n",
       "      <th>built_up</th>\n",
       "      <th>price_psf</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2196.0</td>\n",
       "      <td>1051.85</td>\n",
       "      <td>342.0</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.44</td>\n",
       "      <td>753.0</td>\n",
       "      <td>749.25</td>\n",
       "      <td>398.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3197.0</td>\n",
       "      <td>1955.62</td>\n",
       "      <td>188.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>753.0</td>\n",
       "      <td>784.70</td>\n",
       "      <td>531.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4801.0</td>\n",
       "      <td>3356.08</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1905 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   township_BANDAR BARU SRI PETALING  township_TAMAN TUN DR ISMAIL  \\\n",
       "0                                1.0                           0.0   \n",
       "1                                1.0                           0.0   \n",
       "2                                1.0                           0.0   \n",
       "3                                1.0                           0.0   \n",
       "4                                1.0                           0.0   \n",
       "\n",
       "   township_DAMANSARA HEIGHTS (BUKIT DAMANSARA)  township_TAMAN BUKIT MALURI  \\\n",
       "0                                           0.0                          0.0   \n",
       "1                                           0.0                          0.0   \n",
       "2                                           0.0                          0.0   \n",
       "3                                           0.0                          0.0   \n",
       "4                                           0.0                          0.0   \n",
       "\n",
       "   township_KEPONG BARU  township_OVERSEAS UNION GARDEN  \\\n",
       "0                   0.0                             0.0   \n",
       "1                   0.0                             0.0   \n",
       "2                   0.0                             0.0   \n",
       "3                   0.0                             0.0   \n",
       "4                   0.0                             0.0   \n",
       "\n",
       "   township_HAPPY GARDEN  township_TAMAN MIDAH  township_ALAM DAMAI  \\\n",
       "0                    0.0                   0.0                  0.0   \n",
       "1                    0.0                   0.0                  0.0   \n",
       "2                    0.0                   0.0                  0.0   \n",
       "3                    0.0                   0.0                  0.0   \n",
       "4                    0.0                   0.0                  0.0   \n",
       "\n",
       "   township_TAMAN SRI SINAR  ...  tenure_FREEHOLD  floors  rooms  land_area  \\\n",
       "0                       0.0  ...              0.0     1.0   3.00     2196.0   \n",
       "1                       0.0  ...              0.0     2.0   2.44      753.0   \n",
       "2                       0.0  ...              0.0     2.5   3.70     3197.0   \n",
       "3                       0.0  ...              0.0     2.0   2.40      753.0   \n",
       "4                       0.0  ...              0.0     2.5   4.34     4801.0   \n",
       "\n",
       "   built_up  price_psf      price    year  month   day  \n",
       "0   1051.85      342.0   750000.0  2023.0    6.0   9.0  \n",
       "1    749.25      398.0   300000.0  2023.0    6.0   1.0  \n",
       "2   1955.62      188.0   600000.0  2023.0    5.0  29.0  \n",
       "3    784.70      531.0   400000.0  2023.0    5.0  25.0  \n",
       "4   3356.08      250.0  1200000.0  2023.0    5.0  22.0  \n",
       "\n",
       "[5 rows x 1905 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = IMPUTER_MODEL_DIR / 'rf_multi_imputer.joblib'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    rf_multi_imputer = joblib.load(model_path)\n",
    "else:\n",
    "    rf_multi_imputer = IterativeImputer(estimator=RandomForestRegressor(), random_state=random_state, initial_strategy='median', skip_complete=True)\n",
    "    rf_multi_imputer = rf_multi_imputer.fit(df_transactions_encoded)\n",
    "    joblib.dump(rf_multi_imputer, model_path, compress=('lzma', 9))\n",
    "\n",
    "df_transactions_rf_multi_imputed = pd.DataFrame(rf_multi_imputer.transform(df_transactions_encoded), columns=df_transactions_encoded.columns)\n",
    "df_transactions_rf_multi_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple imputation with random forest took 206m49s to train and impute the data. With models ready, imputation took 2m33s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = IMPUTER_MODEL_DIR / 'knn_multi_imputer.joblib'\n",
    "\n",
    "# if os.path.exists(model_path):\n",
    "#     knn_multi_imputer = joblib.load(model_path)\n",
    "# else:\n",
    "#     knn_multi_imputer = IterativeImputer(estimator=KNeighborsRegressor(), random_state=random_state, initial_strategy='median', skip_complete=True)\n",
    "#     knn_multi_imputer = knn_multi_imputer.fit(df_transactions_encoded)\n",
    "#     joblib.dump(knn_multi_imputer, model_path, compress=('lzma', 9))\n",
    "\n",
    "# df_transactions_knn_multi_imputed = pd.DataFrame(knn_multi_imputer.transform(df_transactions_encoded), columns=df_transactions_encoded.columns)\n",
    "# df_transactions_knn_multi_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = IMPUTER_MODEL_DIR / 'knn_imputer.joblib'\n",
    "\n",
    "# if os.path.exists(model_path):\n",
    "#     knn_imputer = joblib.load(model_path)\n",
    "# else:\n",
    "#     knn_imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "#     knn_imputer = knn_imputer.fit(df_transactions_encoded)\n",
    "#     joblib.dump(knn_imputer, model_path, compress=('lzma', 5))\n",
    "\n",
    "# knn_imputed = knn_imputer.transform(df_transactions_encoded)\n",
    "# df_transactions_knn_imputed = pd.DataFrame(knn_imputed, columns=df_transactions_encoded.columns)\n",
    "# df_transactions_knn_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN imputer did not even finish imputing the data after 610m. When using IterativeImputer with KNNRegressor, MemoryError occured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing `built_up`\n",
    "\n",
    "The steps are:\n",
    "1. Remove `rooms` from the dataset as it has too many missing values\n",
    "2. Cross validate for `built_up` using:\n",
    "    - Random forest imputation\n",
    "    - KNN imputation\n",
    "3. Use the better model to impute `built_up`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'built_up'\n",
    "\n",
    "# Split the dataset into train and test, where train are the data with labels and test are the data without labels\n",
    "data_path = CACHE_DATA_DIR / 'encoded_transactions_train_built_up.parquet'\n",
    "if os.path.exists(data_path):\n",
    "    df_train = pd.read_parquet(data_path)\n",
    "else:\n",
    "    df_train = df_transactions_encoded[df_transactions_encoded[target].notna()].drop(columns=['rooms']).dropna()\n",
    "    df_train.to_parquet(data_path)\n",
    "\n",
    "data_path = CACHE_DATA_DIR / 'encoded_transactions_test_built_up.parquet'\n",
    "if os.path.exists(data_path):\n",
    "    df_test = pd.read_parquet(data_path)\n",
    "else:\n",
    "    df_test = df_transactions_encoded[df_transactions_encoded[target].isna()].drop(columns=['rooms'])\n",
    "    df_test.to_parquet(data_path)\n",
    "\n",
    "# Split the train dataset into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train.drop(columns=[target]), df_train[target], test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross validation for `built_up` using various techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_percentage_error</th>\n",
       "      <th>train_neg_mean_absolute_percentage_error</th>\n",
       "      <th>test_neg_median_absolute_error</th>\n",
       "      <th>train_neg_median_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1221.663679</td>\n",
       "      <td>11.541488</td>\n",
       "      <td>0.824293</td>\n",
       "      <td>0.973771</td>\n",
       "      <td>-357.268651</td>\n",
       "      <td>-136.370194</td>\n",
       "      <td>-4.652190e+15</td>\n",
       "      <td>-1.715361e+15</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200.971122</td>\n",
       "      <td>9.686063</td>\n",
       "      <td>0.798486</td>\n",
       "      <td>0.975722</td>\n",
       "      <td>-379.701082</td>\n",
       "      <td>-131.454077</td>\n",
       "      <td>-5.023980e+15</td>\n",
       "      <td>-1.716289e+15</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233.660341</td>\n",
       "      <td>5.176621</td>\n",
       "      <td>0.854139</td>\n",
       "      <td>0.973795</td>\n",
       "      <td>-316.718636</td>\n",
       "      <td>-137.235538</td>\n",
       "      <td>-2.803023e+15</td>\n",
       "      <td>-1.677708e+15</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1236.589329</td>\n",
       "      <td>6.362303</td>\n",
       "      <td>0.844816</td>\n",
       "      <td>0.973615</td>\n",
       "      <td>-323.399088</td>\n",
       "      <td>-138.035930</td>\n",
       "      <td>-5.624051e+15</td>\n",
       "      <td>-1.652899e+15</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>285.546735</td>\n",
       "      <td>1.645550</td>\n",
       "      <td>0.784114</td>\n",
       "      <td>0.977032</td>\n",
       "      <td>-404.786024</td>\n",
       "      <td>-126.878500</td>\n",
       "      <td>-3.922569e+15</td>\n",
       "      <td>-1.042910e+15</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time   test_r2  train_r2  \\\n",
       "0  1221.663679   11.541488  0.824293  0.973771   \n",
       "1  1200.971122    9.686063  0.798486  0.975722   \n",
       "2  1233.660341    5.176621  0.854139  0.973795   \n",
       "3  1236.589329    6.362303  0.844816  0.973615   \n",
       "4   285.546735    1.645550  0.784114  0.977032   \n",
       "\n",
       "   test_neg_root_mean_squared_error  train_neg_root_mean_squared_error  \\\n",
       "0                       -357.268651                        -136.370194   \n",
       "1                       -379.701082                        -131.454077   \n",
       "2                       -316.718636                        -137.235538   \n",
       "3                       -323.399088                        -138.035930   \n",
       "4                       -404.786024                        -126.878500   \n",
       "\n",
       "   test_neg_mean_absolute_percentage_error  \\\n",
       "0                            -4.652190e+15   \n",
       "1                            -5.023980e+15   \n",
       "2                            -2.803023e+15   \n",
       "3                            -5.624051e+15   \n",
       "4                            -3.922569e+15   \n",
       "\n",
       "   train_neg_mean_absolute_percentage_error  test_neg_median_absolute_error  \\\n",
       "0                             -1.715361e+15                            -0.0   \n",
       "1                             -1.716289e+15                            -0.0   \n",
       "2                             -1.677708e+15                            -0.0   \n",
       "3                             -1.652899e+15                            -0.0   \n",
       "4                             -1.042910e+15                            -0.0   \n",
       "\n",
       "   train_neg_median_absolute_error  \n",
       "0                             -0.0  \n",
       "1                             -0.0  \n",
       "2                             -0.0  \n",
       "3                             -0.0  \n",
       "4                             -0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline with scaler and model\n",
    "rf_pipeline_built_up = Pipeline([('scaler', StandardScaler()), ('model', RandomForestRegressor(random_state=random_state, n_jobs=4))])\n",
    "\n",
    "# Cross validate the pipeline\n",
    "if os.path.exists(IMPUTER_MODEL_DIR / 'cv_results_rf_built_up.joblib'):\n",
    "    cv_results_built_up = joblib.load(IMPUTER_MODEL_DIR / 'cv_results_rf_built_up.joblib')\n",
    "else:\n",
    "    cv_results_built_up = cross_validation_with_pipeline(rf_pipeline_built_up, X_train, y_train, 'regression')\n",
    "    joblib.dump(cv_results_built_up, IMPUTER_MODEL_DIR / 'cv_results_rf_built_up.joblib')\n",
    "\n",
    "pd.DataFrame(cv_results_built_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation using random forest took 55m35s. The results wasn't that great, with substantial RMSE and high MAPE. But it performed well on median-based metrics: median absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_percentage_error</th>\n",
       "      <th>train_neg_mean_absolute_percentage_error</th>\n",
       "      <th>test_neg_median_absolute_error</th>\n",
       "      <th>train_neg_median_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115.349414</td>\n",
       "      <td>842.074621</td>\n",
       "      <td>0.728349</td>\n",
       "      <td>0.807001</td>\n",
       "      <td>-444.228462</td>\n",
       "      <td>-369.920969</td>\n",
       "      <td>-3.509313e+15</td>\n",
       "      <td>-3.596327e+15</td>\n",
       "      <td>-65.8</td>\n",
       "      <td>-51.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.173904</td>\n",
       "      <td>835.366826</td>\n",
       "      <td>0.670352</td>\n",
       "      <td>0.815942</td>\n",
       "      <td>-485.639491</td>\n",
       "      <td>-361.949470</td>\n",
       "      <td>-4.940215e+15</td>\n",
       "      <td>-3.815043e+15</td>\n",
       "      <td>-66.6</td>\n",
       "      <td>-51.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115.667840</td>\n",
       "      <td>844.578770</td>\n",
       "      <td>0.728067</td>\n",
       "      <td>0.805778</td>\n",
       "      <td>-432.449172</td>\n",
       "      <td>-373.617202</td>\n",
       "      <td>-4.629208e+15</td>\n",
       "      <td>-4.027341e+15</td>\n",
       "      <td>-65.7</td>\n",
       "      <td>-51.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114.721992</td>\n",
       "      <td>863.657962</td>\n",
       "      <td>0.714709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-438.488940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.069854e+15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.214992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fit_time  score_time   test_r2  train_r2  \\\n",
       "0  115.349414  842.074621  0.728349  0.807001   \n",
       "1   67.173904  835.366826  0.670352  0.815942   \n",
       "2  115.667840  844.578770  0.728067  0.805778   \n",
       "3  114.721992  863.657962  0.714709       NaN   \n",
       "4   17.214992    0.000000       NaN       NaN   \n",
       "\n",
       "   test_neg_root_mean_squared_error  train_neg_root_mean_squared_error  \\\n",
       "0                       -444.228462                        -369.920969   \n",
       "1                       -485.639491                        -361.949470   \n",
       "2                       -432.449172                        -373.617202   \n",
       "3                       -438.488940                                NaN   \n",
       "4                               NaN                                NaN   \n",
       "\n",
       "   test_neg_mean_absolute_percentage_error  \\\n",
       "0                            -3.509313e+15   \n",
       "1                            -4.940215e+15   \n",
       "2                            -4.629208e+15   \n",
       "3                            -7.069854e+15   \n",
       "4                                      NaN   \n",
       "\n",
       "   train_neg_mean_absolute_percentage_error  test_neg_median_absolute_error  \\\n",
       "0                             -3.596327e+15                           -65.8   \n",
       "1                             -3.815043e+15                           -66.6   \n",
       "2                             -4.027341e+15                           -65.7   \n",
       "3                                       NaN                           -66.0   \n",
       "4                                       NaN                             NaN   \n",
       "\n",
       "   train_neg_median_absolute_error  \n",
       "0                            -51.4  \n",
       "1                            -51.6  \n",
       "2                            -51.4  \n",
       "3                              NaN  \n",
       "4                              NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline with scaler and model\n",
    "knn_pipeline_built_up = Pipeline([('scaler', StandardScaler()), ('model', KNeighborsRegressor(n_jobs=4))])\n",
    "\n",
    "# Cross validate the pipeline\n",
    "if os.path.exists(IMPUTER_MODEL_DIR / 'cv_results_knn_built_up.joblib'):\n",
    "    cv_results_built_up = joblib.load(IMPUTER_MODEL_DIR / 'cv_results_knn_built_up.joblib')\n",
    "else:\n",
    "    cv_results_built_up = cross_validation_with_pipeline(knn_pipeline_built_up, X_train, y_train, 'regression')\n",
    "    joblib.dump(cv_results_built_up, IMPUTER_MODEL_DIR / 'cv_results_knn_built_up.joblib')\n",
    "\n",
    "pd.DataFrame(cv_results_built_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation using KNN took around 148m4s, and then failed at the fourth fold due to insufficient memory. Looking at the results, KNN performed worst then random forest, with higher RMSE, MAPE and median absolute error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check model performance on validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check IterativeImputer models on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for validation set:\n",
      "R2 score: 1.0\n",
      "RMSE score: 0.0\n",
      "MAPE score: 0.0\n",
      "MAE score: 0.0\n",
      "Median AE score: 0.0\n"
     ]
    }
   ],
   "source": [
    "bayesianridge_pred = df_transactions_bayesianridge_multi_imputed[target].iloc[y_val.index]\n",
    "\n",
    "validate_impute(y_val, bayesianridge_pred, 'regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_pred = df_transactions_linreg_multi_imputed[target].iloc[y_val.index]\n",
    "\n",
    "validate_impute(y_val, linreg_pred, 'regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for validation set:\n",
      "R2 score: 1.0\n",
      "RMSE score: 0.0\n",
      "MAPE score: 0.0\n",
      "MAE score: 0.0\n",
      "Median AE score: 0.0\n"
     ]
    }
   ],
   "source": [
    "rf_pred = df_transactions_rf_multi_imputed[target].iloc[y_val.index]\n",
    "\n",
    "validate_impute(y_val, rf_pred, 'regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models perform similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for validation set:\n",
      "R2 score: 0.8080609693884588\n",
      "RMSE score: 381.9099647033172\n",
      "MAPE score: 3890573305511410.5\n",
      "MAE score: 63.87615023388515\n",
      "Median AE score: 0.0\n"
     ]
    }
   ],
   "source": [
    "model_path = IMPUTER_MODEL_DIR / 'rf_pipeline_built_up.joblib'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    rf_pipeline_built_up = joblib.load(model_path)\n",
    "    _ = train_and_validate_model(rf_pipeline_built_up, X_train, y_train, X_val, y_val, 'regression')\n",
    "else:\n",
    "    rf_pipeline_built_up = train_and_validate_model(rf_pipeline_built_up, X_train, y_train, X_val, y_val, 'regression')\n",
    "    joblib.dump(rf_pipeline_built_up, model_path, compress=('lzma', 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest took 6m8s for training on training data and prediction of validation data, and 2.5 second for loading fitted model and predicting validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for validation set:\n",
      "R2 score: 0.6834473458154234\n",
      "RMSE score: 490.45856274893976\n",
      "MAPE score: 4185698477203167.0\n",
      "MAE score: 158.56516414749206\n",
      "Median AE score: 63.200000000000045\n"
     ]
    }
   ],
   "source": [
    "model_path = IMPUTER_MODEL_DIR / 'knn_pipeline_built_up.joblib'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    knn_pipeline_built_up = joblib.load(model_path)\n",
    "    _ = train_and_validate_model(knn_pipeline_built_up, X_train, y_train, X_val, y_val, 'regression')\n",
    "else:\n",
    "    knn_pipeline_built_up = train_and_validate_model(knn_pipeline_built_up, X_train, y_train, X_val, y_val, 'regression')\n",
    "    joblib.dump(knn_pipeline_built_up, model_path, compress=('lzma', 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN took 4m39s for training on training data and prediction of validation data, and 4m54s for loading fitted model and predicting validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing random forest and KNN on both cross validation and validation data, random forest performed better than KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impute `built_up` using the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_with_model(pipeline: Pipeline, df_train: pd.DataFrame, df_test: pd.DataFrame, target: str):\n",
    "\n",
    "    y_test_pred = pipeline.predict(df_test)\n",
    "\n",
    "    df_test[target] = y_test_pred\n",
    "    df_imputed = pd.concat([df_train, df_test])\n",
    "\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 265270 entries, 252 to 75120\n",
      "Columns: 1904 entries, township_BANDAR BARU SRI PETALING to day\n",
      "dtypes: float64(5), int32(3), int64(1896)\n",
      "memory usage: 3.8 GB\n"
     ]
    }
   ],
   "source": [
    "df_test = df_test.drop(columns=[target]).dropna()\n",
    "df_transactions_built_up_imputed = impute_with_model(rf_pipeline_built_up, df_train, df_test, target='built_up')\n",
    "df_transactions_built_up_imputed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Join the imputed `built_up` data with the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 265270 entries, 252 to 75120\n",
      "Columns: 1905 entries, township_BANDAR BARU SRI PETALING to rooms\n",
      "dtypes: float64(6), int32(3), int64(1896)\n",
      "memory usage: 3.8 GB\n"
     ]
    }
   ],
   "source": [
    "df_transactions_built_up_imputed = df_transactions_built_up_imputed.join(df_transactions_encoded['rooms'])\n",
    "df_transactions_built_up_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rooms 29217\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in all columns\n",
    "for column in df_transactions_built_up_imputed.columns:\n",
    "    isna_count = df_transactions_built_up_imputed[column].isna().sum()\n",
    "    if isna_count > 0:\n",
    "        print(column, isna_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing `rooms`\n",
    "\n",
    "The steps are:\n",
    "1. Remove `rooms` with less than 5 samples so that CV can be performed\n",
    "2. Cross validate for `rooms` using:\n",
    "    - Random forest imputation\n",
    "    - KNN imputation\n",
    "3. Use the better model to impute `rooms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'rooms'\n",
    "\n",
    "# Split the dataset into train and test, where train are the data with labels and test are the data without labels\n",
    "data_path = CACHE_DATA_DIR / 'encoded_transactions_train_rooms.parquet'\n",
    "if os.path.exists(data_path):\n",
    "    df_train = pd.read_parquet(data_path)\n",
    "else:\n",
    "    df_train = df_transactions_built_up_imputed[df_transactions_built_up_imputed[target].notna()]\n",
    "    df_train = df_train.groupby(target).filter(lambda x : len(x) > 5).dropna() # Drop rooms with less than 5 samples so that CV can be performed\n",
    "    df_train.to_parquet(data_path)\n",
    "\n",
    "data_path = CACHE_DATA_DIR / 'encoded_transactions_test_rooms.parquet'\n",
    "if os.path.exists(data_path):\n",
    "    df_test = pd.read_parquet(data_path)\n",
    "else:\n",
    "    df_test = df_transactions_built_up_imputed[df_transactions_built_up_imputed[target].isna()]\n",
    "    df_test.to_parquet(data_path)\n",
    "\n",
    "# Split the train dataset into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train.drop(columns=[target]), df_train[target], test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross validation for `rooms` using various techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_percentage_error</th>\n",
       "      <th>train_neg_mean_absolute_percentage_error</th>\n",
       "      <th>test_neg_median_absolute_error</th>\n",
       "      <th>train_neg_median_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.685828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251.693279</td>\n",
       "      <td>10.347663</td>\n",
       "      <td>0.429146</td>\n",
       "      <td>0.996970</td>\n",
       "      <td>-0.734488</td>\n",
       "      <td>-0.052480</td>\n",
       "      <td>-1.645869e+13</td>\n",
       "      <td>-1.788977e+11</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.241544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>241.388860</td>\n",
       "      <td>6.027060</td>\n",
       "      <td>0.456886</td>\n",
       "      <td>0.997788</td>\n",
       "      <td>-0.696532</td>\n",
       "      <td>-0.045157</td>\n",
       "      <td>-1.788988e+13</td>\n",
       "      <td>-1.192651e+11</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>232.804780</td>\n",
       "      <td>6.727474</td>\n",
       "      <td>0.506015</td>\n",
       "      <td>0.997310</td>\n",
       "      <td>-0.666395</td>\n",
       "      <td>-0.049760</td>\n",
       "      <td>-1.908254e+13</td>\n",
       "      <td>-2.981628e+10</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fit_time  score_time   test_r2  train_r2  \\\n",
       "0   28.685828    0.000000       NaN       NaN   \n",
       "1  251.693279   10.347663  0.429146  0.996970   \n",
       "2   51.241544    0.000000       NaN       NaN   \n",
       "3  241.388860    6.027060  0.456886  0.997788   \n",
       "4  232.804780    6.727474  0.506015  0.997310   \n",
       "\n",
       "   test_neg_root_mean_squared_error  train_neg_root_mean_squared_error  \\\n",
       "0                               NaN                                NaN   \n",
       "1                         -0.734488                          -0.052480   \n",
       "2                               NaN                                NaN   \n",
       "3                         -0.696532                          -0.045157   \n",
       "4                         -0.666395                          -0.049760   \n",
       "\n",
       "   test_neg_mean_absolute_percentage_error  \\\n",
       "0                                      NaN   \n",
       "1                            -1.645869e+13   \n",
       "2                                      NaN   \n",
       "3                            -1.788988e+13   \n",
       "4                            -1.908254e+13   \n",
       "\n",
       "   train_neg_mean_absolute_percentage_error  test_neg_median_absolute_error  \\\n",
       "0                                       NaN                             NaN   \n",
       "1                             -1.788977e+11                            -0.0   \n",
       "2                                       NaN                             NaN   \n",
       "3                             -1.192651e+11                            -0.0   \n",
       "4                             -2.981628e+10                            -0.0   \n",
       "\n",
       "   train_neg_median_absolute_error  \n",
       "0                              NaN  \n",
       "1                             -0.0  \n",
       "2                              NaN  \n",
       "3                             -0.0  \n",
       "4                             -0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline with scaler and model\n",
    "rf_pipeline_rooms = Pipeline([('scaler', StandardScaler()), ('model', RandomForestClassifier(random_state=random_state, n_jobs=4))])\n",
    "\n",
    "# Cross validate the pipeline\n",
    "if not os.path.exists(IMPUTER_MODEL_DIR / 'cv_results_rf_rooms.joblib'):\n",
    "    cv_results_rooms = cross_validation_with_pipeline(rf_pipeline_rooms, X_train, y_train, 'regression')\n",
    "    joblib.dump(cv_results_rooms, IMPUTER_MODEL_DIR / 'cv_results_rf_rooms.joblib')\n",
    "else:\n",
    "    cv_results_rooms = joblib.load(IMPUTER_MODEL_DIR / 'cv_results_rf_rooms.joblib')\n",
    "\n",
    "pd.DataFrame(cv_results_rooms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation took 8m5s to complete. There are classes which has only one transactions, therefore the rooms with less than 5 counts were not included for cross validation.\n",
    "\n",
    "From the cross validation results, the model overfits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_percentage_error</th>\n",
       "      <th>train_neg_mean_absolute_percentage_error</th>\n",
       "      <th>test_neg_median_absolute_error</th>\n",
       "      <th>train_neg_median_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.168992</td>\n",
       "      <td>423.701747</td>\n",
       "      <td>0.382646</td>\n",
       "      <td>0.511510</td>\n",
       "      <td>-0.745020</td>\n",
       "      <td>-0.670505</td>\n",
       "      <td>-1.872425e+13</td>\n",
       "      <td>-1.267200e+13</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.414525</td>\n",
       "      <td>406.607987</td>\n",
       "      <td>0.375650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.768132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.443117e+13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.702898</td>\n",
       "      <td>425.574222</td>\n",
       "      <td>0.360377</td>\n",
       "      <td>0.472983</td>\n",
       "      <td>-0.777078</td>\n",
       "      <td>-0.692177</td>\n",
       "      <td>-1.526604e+13</td>\n",
       "      <td>-1.386457e+13</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.375724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.482107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time   test_r2  train_r2  \\\n",
       "0  47.168992  423.701747  0.382646  0.511510   \n",
       "1  98.414525  406.607987  0.375650       NaN   \n",
       "2  51.702898  425.574222  0.360377  0.472983   \n",
       "3  35.375724    0.000000       NaN       NaN   \n",
       "4  59.482107    0.000000       NaN       NaN   \n",
       "\n",
       "   test_neg_root_mean_squared_error  train_neg_root_mean_squared_error  \\\n",
       "0                         -0.745020                          -0.670505   \n",
       "1                         -0.768132                                NaN   \n",
       "2                         -0.777078                          -0.692177   \n",
       "3                               NaN                                NaN   \n",
       "4                               NaN                                NaN   \n",
       "\n",
       "   test_neg_mean_absolute_percentage_error  \\\n",
       "0                            -1.872425e+13   \n",
       "1                            -1.443117e+13   \n",
       "2                            -1.526604e+13   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "\n",
       "   train_neg_mean_absolute_percentage_error  test_neg_median_absolute_error  \\\n",
       "0                             -1.267200e+13                            -0.0   \n",
       "1                                       NaN                            -0.0   \n",
       "2                             -1.386457e+13                            -0.0   \n",
       "3                                       NaN                             NaN   \n",
       "4                                       NaN                             NaN   \n",
       "\n",
       "   train_neg_median_absolute_error  \n",
       "0                             -0.0  \n",
       "1                              NaN  \n",
       "2                             -0.0  \n",
       "3                              NaN  \n",
       "4                              NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline with scaler and model\n",
    "knn_pipeline_rooms = Pipeline([('scaler', StandardScaler()), ('model', KNeighborsClassifier(n_jobs=4))])\n",
    "\n",
    "# Cross validate the pipeline\n",
    "if not os.path.exists(IMPUTER_MODEL_DIR / 'cv_results_knn_rooms.joblib'):\n",
    "    cv_results_rooms = cross_validation_with_pipeline(knn_pipeline_rooms, X_train, y_train, 'regression')\n",
    "    joblib.dump(cv_results_rooms, IMPUTER_MODEL_DIR / 'cv_results_knn_rooms.joblib')\n",
    "else:\n",
    "    cv_results_rooms = joblib.load(IMPUTER_MODEL_DIR / 'cv_results_knn_rooms.joblib')\n",
    "\n",
    "pd.DataFrame(cv_results_rooms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check model performance on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for validation set:\n",
      "Accuracy score: 1.0\n",
      "Balanced accuracy score: 1.0\n",
      "Macro F1 score: 1.0\n",
      "Weighted F1 score: 1.0\n",
      "Macro precision score: 1.0\n",
      "Weighted precision score: 1.0\n",
      "Macro recall score: 1.0\n",
      "Weighted recall score: 1.0\n"
     ]
    }
   ],
   "source": [
    "bayesianridge_pred = df_transactions_bayesianridge_multi_imputed[target].iloc[y_val.index]\n",
    "\n",
    "validate_impute(y_val, bayesianridge_pred, 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for validation set:\n",
      "Accuracy score: 1.0\n",
      "Balanced accuracy score: 1.0\n",
      "Macro F1 score: 1.0\n",
      "Weighted F1 score: 1.0\n",
      "Macro precision score: 1.0\n",
      "Weighted precision score: 1.0\n",
      "Macro recall score: 1.0\n",
      "Weighted recall score: 1.0\n"
     ]
    }
   ],
   "source": [
    "rf_pred = df_transactions_rf_multi_imputed[target].iloc[y_val.index]\n",
    "\n",
    "validate_impute(y_val, rf_pred, 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for validation set:\n",
      "Accuracy score: 0.8350705478581416\n",
      "Balanced accuracy score: 0.33657015622976827\n",
      "Macro F1 score: 0.376981223121691\n",
      "Weighted F1 score: 0.831617850387697\n",
      "Macro precision score: 0.4883131102823608\n",
      "Weighted precision score: 0.831007007869572\n",
      "Macro recall score: 0.33657015622976827\n",
      "Weighted recall score: 0.8350705478581416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_path = IMPUTER_MODEL_DIR / 'rf_pipeline_rooms.joblib'\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    rf_pipeline_rooms = train_and_validate_model(rf_pipeline_rooms, X_train, y_train, X_val, y_val, 'classification')\n",
    "    joblib.dump(rf_pipeline_rooms, model_path, compress=('lzma', 9))\n",
    "else:\n",
    "    rf_pipeline_rooms = joblib.load(model_path)\n",
    "    _ = train_and_validate_model(rf_pipeline_rooms, X_train, y_train, X_val, y_val, 'classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline took 4m54s to train and predict. However, the results were not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for validation set:\n",
      "Accuracy score: 0.804902334646837\n",
      "Balanced accuracy score: 0.3300829740211839\n",
      "Macro F1 score: 0.3648131769531161\n",
      "Weighted F1 score: 0.802039007879012\n",
      "Macro precision score: 0.4476826414403684\n",
      "Weighted precision score: 0.8007987364640089\n",
      "Macro recall score: 0.3300829740211839\n",
      "Weighted recall score: 0.804902334646837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Repos\\GitHub\\time-series-house-price-forecasting\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_path = IMPUTER_MODEL_DIR / 'knn_pipeline_rooms.joblib'\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    knn_pipeline_rooms = train_and_validate_model(knn_pipeline_rooms, X_train, y_train, X_val, y_val, 'classification')\n",
    "    joblib.dump(knn_pipeline_rooms, model_path, compress=('lzma', 9))\n",
    "else:\n",
    "    knn_pipeline_rooms = joblib.load(model_path)\n",
    "    _ = train_and_validate_model(knn_pipeline_rooms, X_train, y_train, X_val, y_val, 'classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline took 5m15s to train and predict. However, the results were competitive but not superior than random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impute `rooms` using the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 265225 entries, 252 to 75120\n",
      "Columns: 1905 entries, township_BANDAR BARU SRI PETALING to rooms\n",
      "dtypes: float64(6), int32(3), int64(1896)\n",
      "memory usage: 3.8 GB\n"
     ]
    }
   ],
   "source": [
    "df_test = df_test.drop(columns=[target]).dropna()\n",
    "df_transactions_rooms_imputed = impute_with_model(rf_pipeline_rooms, df_train, df_test, target='rooms')\n",
    "df_transactions_rooms_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_transactions_rooms_imputed.columns:\n",
    "    isna_count = df_transactions_rooms_imputed[column].isna().sum()\n",
    "    if isna_count > 0:\n",
    "        print(column, isna_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions_rooms_imputed.to_parquet(TRANSFORMED_DATA_DIR / 'transactions_KL_ckpt5_imputed_manual.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions_bayesianridge_multi_imputed.to_parquet(TRANSFORMED_DATA_DIR / 'transactions_KL_ckpt5_multi_imputed_bayesianridge.parquet')\n",
    "df_transactions_rf_multi_imputed.to_parquet(TRANSFORMED_DATA_DIR / 'transactions_KL_ckpt5_multi_imputed_rf.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Bayesian-ridge imputed data for subsequent process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
